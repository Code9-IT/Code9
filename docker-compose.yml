# =============================================================
# Maritime Agentic Observability – Docker Compose
# =============================================================
# Quick start:
#   cp .env.example .env
#   docker compose up --build
#   docker exec -it maritime_ollama ollama pull llama3.2
#
# Services:
#   timescaledb  – time-series database (PostgreSQL + TimescaleDB)
#   grafana      – dashboards (auto-provisioned)
#   agent        – FastAPI AI-agent (event analysis + tool-calling loop)
#   generator    – synthetic telemetry + anomaly writer
#   mcp          – MCP-style REST adapter (exposes DB tools to agent)
#   ollama       – local LLM (llama3.2 – pull model after first start)
# =============================================================

version: '3.8'

services:
  # ─── TIME-SERIES DATABASE ─────────────────────────────────
  timescaledb:
    image: timescale/timescaledb-postgis:latest-pg16
    container_name: maritime_timescaledb
    environment:
      POSTGRES_USER:     ${DB_USER:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}
      POSTGRES_DB:       ${DB_NAME:-maritime_telemetry}
    ports:
      - "${DB_PORT:-5432}:5432"
    volumes:
      - ./db/init:/docker-entrypoint-initdb.d   # 001_init.sql runs on first start
      - timescaledb_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d maritime_telemetry"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  # ─── GRAFANA ──────────────────────────────────────────────
  grafana:
    image: grafana/grafana:11.0.0
    container_name: maritime_grafana
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    environment:
      GF_SECURITY_ADMIN_USER:     ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
      GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH: /var/lib/grafana/dashboards/ship_operations.json
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      timescaledb:
        condition: service_healthy
    restart: unless-stopped

  # ─── AI AGENT SERVICE (FastAPI) ───────────────────────────
  agent:
    build:
      context:    ./services/agent
      dockerfile: Dockerfile
    container_name: maritime_agent
    ports:
      - "${AGENT_PORT:-8000}:8000"
    environment:
      DB_HOST:     timescaledb
      DB_PORT:     "5432"
      DB_USER:     ${DB_USER:-postgres}
      DB_PASSWORD: ${DB_PASSWORD:-postgres}
      DB_NAME:     ${DB_NAME:-maritime_telemetry}
      OLLAMA_URL:   ${OLLAMA_URL:-http://ollama:11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2}
      MCP_URL:      ${MCP_URL:-http://mcp:8001}
      STUB_MODE:    ${STUB_MODE:-false}
    depends_on:
      timescaledb:
        condition: service_healthy
      mcp:
        condition: service_started
      ollama:
        condition: service_started
    restart: unless-stopped

  # ─── MCP SERVER (REST adapter exposing DB tools) ──────────
  mcp:
    build:
      context:    ./services/mcp
      dockerfile: Dockerfile
    container_name: maritime_mcp
    ports:
      - "${MCP_PORT:-8001}:8001"
    environment:
      DB_HOST:     timescaledb
      DB_PORT:     "5432"
      DB_USER:     ${DB_USER:-postgres}
      DB_PASSWORD: ${DB_PASSWORD:-postgres}
      DB_NAME:     ${DB_NAME:-maritime_telemetry}
    depends_on:
      timescaledb:
        condition: service_healthy
    restart: unless-stopped

  # ─── SYNTHETIC DATA GENERATOR ─────────────────────────────
  generator:
    build:
      context:    ./services/generator
      dockerfile: Dockerfile
    container_name: maritime_generator
    environment:
      DB_HOST:     timescaledb
      DB_PORT:     "5432"
      DB_USER:     ${DB_USER:-postgres}
      DB_PASSWORD: ${DB_PASSWORD:-postgres}
      DB_NAME:     ${DB_NAME:-maritime_telemetry}
      GENERATE_INTERVAL_SECONDS: ${GENERATE_INTERVAL_SECONDS:-3}
      # With 77 threshold combinations: P(event/cycle) = 1-(1-p)^77.
      # 0.00008 → P≈0.6% per cycle → ~1 event per 8 minutes at 3s interval.
      ANOMALY_PROBABILITY:       ${ANOMALY_PROBABILITY:-0.00008}
    depends_on:
      timescaledb:
        condition: service_healthy
    restart: unless-stopped

  # ─── OLLAMA – local LLM ───────────────────────────────────
  # After first start, pull a model:
  #   docker exec -it maritime_ollama ollama pull llama3.2
  # For better quality (needs ~8 GB RAM):
  #   docker exec -it maritime_ollama ollama pull llama3.1
  ollama:
    image: ollama/ollama:latest
    container_name: maritime_ollama
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped

# ─── VOLUMES ──────────────────────────────────────────────
volumes:
  timescaledb_data:
  ollama_data:
